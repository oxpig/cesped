<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>cesped.datamanager.augmentations API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>cesped.datamanager.augmentations</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import os.path as osp
import functools
import random
from typing import Optional, Dict, Tuple

import numpy as np
import torch
import torch.nn.functional as F
from omegaconf import OmegaConf
from scipy.spatial.transform import Rotation
from torchvision.transforms import ToTensor
from torchvision.transforms.v2 import RandomErasing
import torchvision.transforms.functional as transformF
from cesped.constants import default_configs_dir


# TODO: Implement augmentations in a better way, defining custom torchvision operations so that they can be used in batch mode seamingly.

class Augmenter:
    def __init__(self,
                 configFname:Optional[str] = None,
                 min_n_augm_per_img: Optional[int] = None,
                 max_n_augm_per_img: Optional[int] = None):

        augmentConfig = self.read_config(configFname)
        self._augmentationTypes = augmentConfig.operations
        self.augmentationTypes = self._augmentationTypes.copy()  # We have self._augmentationTypes in case we want to reset probs

        self.min_n_augm_per_img = augmentConfig.min_n_augm_per_img if (
                    min_n_augm_per_img is None) else min_n_augm_per_img
        self.max_n_augm_per_img = augmentConfig.max_n_augm_per_img if (
                    max_n_augm_per_img is None) else max_n_augm_per_img

        self.probSchedulers = {name: Scheduler(vals.get(&#34;probScheduler&#34;)).generate() for name, vals in
                               self.augmentationTypes.items()}

        self.augmentation_count = 0

    @classmethod
    def read_config(cls, fname=None):
        if fname is None:
            return OmegaConf.load(osp.join(default_configs_dir, &#34;defaultDataAugmentation.yaml&#34;))
        else:
            return OmegaConf.load(osp.join(fname))

    @functools.lru_cache(1)
    def _getRandomEraser(self, **kwargs):
        return RandomErasing(p=1., **kwargs)

    def _randomErase(self, img, **kwargs):
        eraser = self._getRandomEraser(**kwargs)
        return eraser(img)

    def _get_nrounds(self):
        return random.randint(self.min_n_augm_per_img, self.max_n_augm_per_img)

    def _get_rand(self):
        return random.random()

    def applyAugmentation(self, imgs, degEulerList, shiftFractionList):
        if len(imgs.shape) &gt; 3: #TODO: Better batch mode
            transformed_batch = []
            degEulerList_ = []
            shiftFractionList_ = []
            applied_transforms_ = []
            for img, euler, shift in zip(imgs, degEulerList, shiftFractionList):
                (transformed_img, euler, shift,
                 applied_transforms) = self._applyAugmentation(img, euler, shift)
                transformed_batch.append(transformed_img)
                degEulerList_.append(euler)
                shiftFractionList_.append(shift)
                applied_transforms_ += [applied_transforms]
            return torch.stack(transformed_batch, dim=0), torch.stack(degEulerList_, dim=0), \
                torch.stack(shiftFractionList_, dim=0), applied_transforms_
        else:
            return self._applyAugmentation(imgs, degEulerList, shiftFractionList)

    def _applyAugmentation(self, img, degEuler, shiftFraction):
        &#34;&#34;&#34;

        Args:
            img: A tensor of shape 1XLxL
            degEuler:
            shiftFraction:

        Returns:

        &#34;&#34;&#34;
        img = img.clone()
        applied_transforms = []
        n_rounds = self._get_nrounds()
        for round in range(n_rounds):
            for aug, v in self.augmentationTypes.items():
                aug_kwargs = v[&#34;kwargs&#34;]
                p = self.probSchedulers[aug](v[&#34;p&#34;], self.augmentation_count)
                if self._get_rand() &lt; p:
                    if aug == &#34;randomGaussNoise&#34;:
                        scale = random.random() * aug_kwargs[&#34;scale&#34;]
                        applied_transforms.append((aug, dict(scale=scale)))
                        img += torch.randn_like(img) * scale
                    elif aug == &#34;randomUnifNoise&#34;:
                        scale = random.random() * aug_kwargs[&#34;scale&#34;]
                        img += (torch.rand_like(img) - 0.5) * scale
                        applied_transforms.append((aug, dict(scale=scale)))

                    elif aug == &#34;inPlaneRotations90&#34;:
                        rotOrder = random.randint(0, 3)
                        img = torch.rot90(img, rotOrder, [-2, -1])
                        degEuler[-1] = (degEuler[-1] + 90. * rotOrder) % 360
                        applied_transforms.append((aug, dict(rotOrder=rotOrder)))

                    elif aug == &#34;inPlaneRotations&#34;:
                        randDeg = (torch.rand(1) - 0.5) * aug_kwargs[&#34;maxDegrees&#34;]
                        img, theta = rotTransImage(img.unsqueeze(0), randDeg, translationFract=torch.zeros(1),
                                                   scaling=1)
                        img = img.squeeze(0)
                        degEuler[-1] = (degEuler[-1] + randDeg.item()) % 360
                        applied_transforms.append((aug, dict(randDeg=randDeg)))

                    elif aug == &#34;inPlaneShifts&#34;:  # It is important to do rotations before shifts

                        randFractionShifts = (torch.rand(2) - 0.5) * aug_kwargs[&#34;maxShiftFraction&#34;]
                        img = rotTransImage(img.unsqueeze(0), torch.zeros(1), translationFract=randFractionShifts,
                                            scaling=1)[0].squeeze(0)
                        shiftFraction += randFractionShifts
                        applied_transforms.append((aug, dict(randFractionShifts=randFractionShifts)))

                    elif aug == &#34;sizePerturbation&#34;:
                        scale = 1 + (random.random() - 0.5) * aug_kwargs[&#34;maxSizeFraction&#34;]
                        img = rotTransImage(img.unsqueeze(0), torch.zeros(1), translationFract=torch.zeros(2),
                                            scaling=torch.FloatTensor([scale]))[0].squeeze(0)
                        applied_transforms.append((aug, dict(scale=scale)))

                    elif aug == &#34;gaussianBlur&#34;:
                        scale = 1e-3 + (1 + (random.random() - 0.5) * aug_kwargs[&#34;scale&#34;])
                        img = transformF.gaussian_blur(img, kernel_size=3 + 2 * int(scale), sigma=scale)
                        applied_transforms.append((aug, dict(scale=scale)))

                    elif aug == &#34;erasing&#34;:
                        kwargs = {k: tuple(v) for k, v in aug_kwargs.items()}
                        img = self._randomErase(img, **kwargs)
                        applied_transforms.append((aug, dict(kwargs=kwargs)))
                    else:
                        raise ValueError(f&#34;Error, unknown augmentation {aug}&#34;)
        self.augmentation_count += 1
        return img, degEuler, shiftFraction, applied_transforms

    def __call__(self, img, eulersDeg, shiftFraction):
        return self.applyAugmentation(img, eulersDeg, shiftFraction)



def rotTransImage(image, degrees, translationFract, scaling=1., padding_mode=&#39;reflection&#39;,
                  interpolation_mode=&#34;bilinear&#34;, rotation_first=True) -&gt; Tuple[torch.Tensor, torch.Tensor]:
    &#34;&#34;&#34;

    :param image: BxCxNxN
    :param degrees:
    :param translationFract: The translation to be applied as a fraction of the total size in pixels
    :param scaling:
    :param padding_mode:
    :param interpolation_mode:
    :param rotation_first: if using to compute Relion alignment parameters, set it to True
    :return:
    &#34;&#34;&#34;
    align_corners = True  # If set to True, the extrema (-1 and 1) are considered as referring to the center points of the input’s corner pixels. If set to False, they are instead considered as referring to the corner points of the input’s corner pixels, making the sampling more resolution agnostic.
    assert ((-1 &lt; translationFract) &amp; (translationFract &lt; 1)).all(), \
        (f&#34;Error, translation should be provided as a fraction of the image.&#34;
         f&#34; {translationFract.min()} {translationFract.max()} &#34;)
    radians = torch.deg2rad(degrees)
    cosAngle = torch.cos(radians)
    sinAngle = torch.sin(radians)

    # theta = torch.stack([cosAngle, -sinAngle, translation[..., 0:1], sinAngle, cosAngle, translation[..., 1:2]], -1).view(-1, 2, 3)

    noTransformation = torch.eye(3).unsqueeze(0).repeat(sinAngle.shape[0], 1, 1).to(sinAngle.device)
    rotMat = noTransformation.clone()
    rotMat[:, :2, :2] = torch.stack([cosAngle, -sinAngle, sinAngle, cosAngle], -1).view(-1, 2, 2)

    transMat = noTransformation.clone()
    transMat[:, :2, -1] = translationFract

    if rotation_first:
        theta = torch.bmm(rotMat, transMat)[:, :2, :]
    else:
        theta = torch.bmm(transMat, rotMat)[:, :2, :]

    # raise NotImplementedError(&#34;TODO: check if this is how to do it, rotTrans rather than transRot&#34;)
    if scaling != 1:
        theta[:, 0, 0] *= scaling
        theta[:, 1, 1] *= scaling

    if len(image.shape) == 3:
        image = image.unsqueeze(0)
    # Generate the grid for the transformation
    grid = F.affine_grid(
        theta,
        size=image.shape,
        align_corners=align_corners,
    )

    # Perform the affine transformation with automatic padding
    image = F.grid_sample(
        image,
        grid,
        padding_mode=padding_mode,
        align_corners=align_corners,
        mode=interpolation_mode

    )
    return image, theta

def _generate_scheduler(schedulerInfo):
    if schedulerInfo is None:
        def _identity(x, current_step):
            return x
        return _identity
    else:
        schedulerName = schedulerInfo[&#34;type&#34;]
        schedulerKwargs = schedulerInfo[&#34;kwargs&#34;]
        if schedulerName == &#34;linear_up&#34;:
            maxProb = schedulerKwargs.get(&#34;max_prob&#34;)
            scheduler_steps = schedulerKwargs.get(&#34;scheduler_steps&#34;)

            def linear_up(p, current_step):
                # Linearly increase from 0 to p over scheduler_steps
                increment = (maxProb - p) / scheduler_steps
                new_p = min(p + increment * current_step, maxProb)
                return new_p

            return linear_up
        elif schedulerName == &#34;linear_down&#34;:
            scheduler_steps = schedulerKwargs.get(&#34;scheduler_steps&#34;)
            minProb = schedulerKwargs.get(&#34;min_prob&#34;)

            def linear_down(p, current_step):
                # Linearly decrease from p to min_prob over scheduler_steps
                decrement = (p - minProb) / scheduler_steps
                new_p = max(p - decrement * current_step, minProb)
                return new_p

            return linear_down
        else:
            raise NotImplementedError(f&#34;False {schedulerName} is not valid&#34;)

class Scheduler:
    def __init__(self, schedulerInfo):
        self.schedulerInfo = schedulerInfo

    def identity(self, x, current_step):
        return x

    def linear_up(self, p, current_step):
        maxProb = self.schedulerInfo[&#34;kwargs&#34;].get(&#34;max_prob&#34;)
        scheduler_steps = self.schedulerInfo[&#34;kwargs&#34;].get(&#34;scheduler_steps&#34;)
        increment = (maxProb - p) / scheduler_steps
        return min(p + increment * current_step, maxProb)

    def linear_down(self, p, current_step):
        scheduler_steps = self.schedulerInfo[&#34;kwargs&#34;].get(&#34;scheduler_steps&#34;)
        minProb = self.schedulerInfo[&#34;kwargs&#34;].get(&#34;min_prob&#34;)
        decrement = (p - minProb) / scheduler_steps
        return max(p - decrement * current_step, minProb)

    def generate(self):
        if self.schedulerInfo is None:
            return self.identity
        else:
            schedulerName = self.schedulerInfo[&#34;type&#34;]
            if schedulerName == &#34;linear_up&#34;:
                return self.linear_up
            elif schedulerName == &#34;linear_down&#34;:
                return self.linear_down
            else:
                raise NotImplementedError(f&#34;{schedulerName} is not valid&#34;)

if __name__ == &#34;__main__&#34;:
    augmentKwargs = Augmenter.read_config()
    print(augmentKwargs)
    # augmentKwargs[&#34;operations&#34;] = {&#39;randomGaussNoise&#39;: {&#39;kwargs&#39;: {&#39;scale&#39;: 0.5}, &#39;p&#39;: 1.}}
    # augmentKwargs[&#34;operations&#34;] = {&#39;randomUnifNoise&#39;: {&#39;kwargs&#39;: {&#39;scale&#39;: 2}, &#39;p&#39;: 1.}}
    # augmentKwargs[&#34;operations&#34;] = {&#39;inPlaneRotations90&#39;: {&#39;kwargs&#39;: {&#39;scale&#39;: 2}, &#39;p&#39;: 1.}}

    from cesped.particlesDataset import ParticlesDataset

    # dataset = ParticlesDataset(&#34;TEST&#34;, 0)
    from torchvision.datasets import CIFAR100

    dataset = CIFAR100(root=&#34;/tmp/cifcar&#34;, transform=ToTensor(), download=True)

    augmenter = Augmenter(**augmentKwargs)
    # augmenter._get_rand = lambda: 0
    from torch.utils.data import DataLoader

    dl = DataLoader(dataset, batch_size=4, num_workers=0, shuffle=False)
    for batch in dl:
        # _, img, (rotmat, shiftAngs, conf), *_ = batch; shiftFrac = shifstAngs/(2*datset.image_size)
        img, *_ = batch[0].unsqueeze(1)
        eulers = torch.from_numpy(Rotation.random(batch[0].shape[0]).as_matrix().astype(np.float32));
        shiftFrac = torch.zeros(batch[0].shape[0], 2)
        print(img.shape)
        img_, eulers_, shiftFrac_, applied_transforms = augmenter.applyAugmentation(img, eulers, shiftFrac)
        from matplotlib import pyplot as plt

        f, axes = plt.subplots(1, 2)
        for i in range(img.shape[0]):
            print(applied_transforms[i])
            axes.flat[0].imshow(img[i, ...].permute(1, 2, 0))  # , cmap=&#34;gray&#34;)
            axes.flat[1].imshow(img_[i, ...].permute(1, 2, 0))  # , cmap=&#34;gray&#34;)
            plt.show()
            print()
            print()
        # break</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="cesped.datamanager.augmentations.rotTransImage"><code class="name flex">
<span>def <span class="ident">rotTransImage</span></span>(<span>image, degrees, translationFract, scaling=1.0, padding_mode='reflection', interpolation_mode='bilinear', rotation_first=True) ‑> Tuple[torch.Tensor, torch.Tensor]</span>
</code></dt>
<dd>
<div class="desc"><p>:param image: BxCxNxN
:param degrees:
:param translationFract: The translation to be applied as a fraction of the total size in pixels
:param scaling:
:param padding_mode:
:param interpolation_mode:
:param rotation_first: if using to compute Relion alignment parameters, set it to True
:return:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def rotTransImage(image, degrees, translationFract, scaling=1., padding_mode=&#39;reflection&#39;,
                  interpolation_mode=&#34;bilinear&#34;, rotation_first=True) -&gt; Tuple[torch.Tensor, torch.Tensor]:
    &#34;&#34;&#34;

    :param image: BxCxNxN
    :param degrees:
    :param translationFract: The translation to be applied as a fraction of the total size in pixels
    :param scaling:
    :param padding_mode:
    :param interpolation_mode:
    :param rotation_first: if using to compute Relion alignment parameters, set it to True
    :return:
    &#34;&#34;&#34;
    align_corners = True  # If set to True, the extrema (-1 and 1) are considered as referring to the center points of the input’s corner pixels. If set to False, they are instead considered as referring to the corner points of the input’s corner pixels, making the sampling more resolution agnostic.
    assert ((-1 &lt; translationFract) &amp; (translationFract &lt; 1)).all(), \
        (f&#34;Error, translation should be provided as a fraction of the image.&#34;
         f&#34; {translationFract.min()} {translationFract.max()} &#34;)
    radians = torch.deg2rad(degrees)
    cosAngle = torch.cos(radians)
    sinAngle = torch.sin(radians)

    # theta = torch.stack([cosAngle, -sinAngle, translation[..., 0:1], sinAngle, cosAngle, translation[..., 1:2]], -1).view(-1, 2, 3)

    noTransformation = torch.eye(3).unsqueeze(0).repeat(sinAngle.shape[0], 1, 1).to(sinAngle.device)
    rotMat = noTransformation.clone()
    rotMat[:, :2, :2] = torch.stack([cosAngle, -sinAngle, sinAngle, cosAngle], -1).view(-1, 2, 2)

    transMat = noTransformation.clone()
    transMat[:, :2, -1] = translationFract

    if rotation_first:
        theta = torch.bmm(rotMat, transMat)[:, :2, :]
    else:
        theta = torch.bmm(transMat, rotMat)[:, :2, :]

    # raise NotImplementedError(&#34;TODO: check if this is how to do it, rotTrans rather than transRot&#34;)
    if scaling != 1:
        theta[:, 0, 0] *= scaling
        theta[:, 1, 1] *= scaling

    if len(image.shape) == 3:
        image = image.unsqueeze(0)
    # Generate the grid for the transformation
    grid = F.affine_grid(
        theta,
        size=image.shape,
        align_corners=align_corners,
    )

    # Perform the affine transformation with automatic padding
    image = F.grid_sample(
        image,
        grid,
        padding_mode=padding_mode,
        align_corners=align_corners,
        mode=interpolation_mode

    )
    return image, theta</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="cesped.datamanager.augmentations.Augmenter"><code class="flex name class">
<span>class <span class="ident">Augmenter</span></span>
<span>(</span><span>configFname: Optional[str] = None, min_n_augm_per_img: Optional[int] = None, max_n_augm_per_img: Optional[int] = None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Augmenter:
    def __init__(self,
                 configFname:Optional[str] = None,
                 min_n_augm_per_img: Optional[int] = None,
                 max_n_augm_per_img: Optional[int] = None):

        augmentConfig = self.read_config(configFname)
        self._augmentationTypes = augmentConfig.operations
        self.augmentationTypes = self._augmentationTypes.copy()  # We have self._augmentationTypes in case we want to reset probs

        self.min_n_augm_per_img = augmentConfig.min_n_augm_per_img if (
                    min_n_augm_per_img is None) else min_n_augm_per_img
        self.max_n_augm_per_img = augmentConfig.max_n_augm_per_img if (
                    max_n_augm_per_img is None) else max_n_augm_per_img

        self.probSchedulers = {name: Scheduler(vals.get(&#34;probScheduler&#34;)).generate() for name, vals in
                               self.augmentationTypes.items()}

        self.augmentation_count = 0

    @classmethod
    def read_config(cls, fname=None):
        if fname is None:
            return OmegaConf.load(osp.join(default_configs_dir, &#34;defaultDataAugmentation.yaml&#34;))
        else:
            return OmegaConf.load(osp.join(fname))

    @functools.lru_cache(1)
    def _getRandomEraser(self, **kwargs):
        return RandomErasing(p=1., **kwargs)

    def _randomErase(self, img, **kwargs):
        eraser = self._getRandomEraser(**kwargs)
        return eraser(img)

    def _get_nrounds(self):
        return random.randint(self.min_n_augm_per_img, self.max_n_augm_per_img)

    def _get_rand(self):
        return random.random()

    def applyAugmentation(self, imgs, degEulerList, shiftFractionList):
        if len(imgs.shape) &gt; 3: #TODO: Better batch mode
            transformed_batch = []
            degEulerList_ = []
            shiftFractionList_ = []
            applied_transforms_ = []
            for img, euler, shift in zip(imgs, degEulerList, shiftFractionList):
                (transformed_img, euler, shift,
                 applied_transforms) = self._applyAugmentation(img, euler, shift)
                transformed_batch.append(transformed_img)
                degEulerList_.append(euler)
                shiftFractionList_.append(shift)
                applied_transforms_ += [applied_transforms]
            return torch.stack(transformed_batch, dim=0), torch.stack(degEulerList_, dim=0), \
                torch.stack(shiftFractionList_, dim=0), applied_transforms_
        else:
            return self._applyAugmentation(imgs, degEulerList, shiftFractionList)

    def _applyAugmentation(self, img, degEuler, shiftFraction):
        &#34;&#34;&#34;

        Args:
            img: A tensor of shape 1XLxL
            degEuler:
            shiftFraction:

        Returns:

        &#34;&#34;&#34;
        img = img.clone()
        applied_transforms = []
        n_rounds = self._get_nrounds()
        for round in range(n_rounds):
            for aug, v in self.augmentationTypes.items():
                aug_kwargs = v[&#34;kwargs&#34;]
                p = self.probSchedulers[aug](v[&#34;p&#34;], self.augmentation_count)
                if self._get_rand() &lt; p:
                    if aug == &#34;randomGaussNoise&#34;:
                        scale = random.random() * aug_kwargs[&#34;scale&#34;]
                        applied_transforms.append((aug, dict(scale=scale)))
                        img += torch.randn_like(img) * scale
                    elif aug == &#34;randomUnifNoise&#34;:
                        scale = random.random() * aug_kwargs[&#34;scale&#34;]
                        img += (torch.rand_like(img) - 0.5) * scale
                        applied_transforms.append((aug, dict(scale=scale)))

                    elif aug == &#34;inPlaneRotations90&#34;:
                        rotOrder = random.randint(0, 3)
                        img = torch.rot90(img, rotOrder, [-2, -1])
                        degEuler[-1] = (degEuler[-1] + 90. * rotOrder) % 360
                        applied_transforms.append((aug, dict(rotOrder=rotOrder)))

                    elif aug == &#34;inPlaneRotations&#34;:
                        randDeg = (torch.rand(1) - 0.5) * aug_kwargs[&#34;maxDegrees&#34;]
                        img, theta = rotTransImage(img.unsqueeze(0), randDeg, translationFract=torch.zeros(1),
                                                   scaling=1)
                        img = img.squeeze(0)
                        degEuler[-1] = (degEuler[-1] + randDeg.item()) % 360
                        applied_transforms.append((aug, dict(randDeg=randDeg)))

                    elif aug == &#34;inPlaneShifts&#34;:  # It is important to do rotations before shifts

                        randFractionShifts = (torch.rand(2) - 0.5) * aug_kwargs[&#34;maxShiftFraction&#34;]
                        img = rotTransImage(img.unsqueeze(0), torch.zeros(1), translationFract=randFractionShifts,
                                            scaling=1)[0].squeeze(0)
                        shiftFraction += randFractionShifts
                        applied_transforms.append((aug, dict(randFractionShifts=randFractionShifts)))

                    elif aug == &#34;sizePerturbation&#34;:
                        scale = 1 + (random.random() - 0.5) * aug_kwargs[&#34;maxSizeFraction&#34;]
                        img = rotTransImage(img.unsqueeze(0), torch.zeros(1), translationFract=torch.zeros(2),
                                            scaling=torch.FloatTensor([scale]))[0].squeeze(0)
                        applied_transforms.append((aug, dict(scale=scale)))

                    elif aug == &#34;gaussianBlur&#34;:
                        scale = 1e-3 + (1 + (random.random() - 0.5) * aug_kwargs[&#34;scale&#34;])
                        img = transformF.gaussian_blur(img, kernel_size=3 + 2 * int(scale), sigma=scale)
                        applied_transforms.append((aug, dict(scale=scale)))

                    elif aug == &#34;erasing&#34;:
                        kwargs = {k: tuple(v) for k, v in aug_kwargs.items()}
                        img = self._randomErase(img, **kwargs)
                        applied_transforms.append((aug, dict(kwargs=kwargs)))
                    else:
                        raise ValueError(f&#34;Error, unknown augmentation {aug}&#34;)
        self.augmentation_count += 1
        return img, degEuler, shiftFraction, applied_transforms

    def __call__(self, img, eulersDeg, shiftFraction):
        return self.applyAugmentation(img, eulersDeg, shiftFraction)</code></pre>
</details>
<h3>Static methods</h3>
<dl>
<dt id="cesped.datamanager.augmentations.Augmenter.read_config"><code class="name flex">
<span>def <span class="ident">read_config</span></span>(<span>fname=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@classmethod
def read_config(cls, fname=None):
    if fname is None:
        return OmegaConf.load(osp.join(default_configs_dir, &#34;defaultDataAugmentation.yaml&#34;))
    else:
        return OmegaConf.load(osp.join(fname))</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="cesped.datamanager.augmentations.Augmenter.applyAugmentation"><code class="name flex">
<span>def <span class="ident">applyAugmentation</span></span>(<span>self, imgs, degEulerList, shiftFractionList)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def applyAugmentation(self, imgs, degEulerList, shiftFractionList):
    if len(imgs.shape) &gt; 3: #TODO: Better batch mode
        transformed_batch = []
        degEulerList_ = []
        shiftFractionList_ = []
        applied_transforms_ = []
        for img, euler, shift in zip(imgs, degEulerList, shiftFractionList):
            (transformed_img, euler, shift,
             applied_transforms) = self._applyAugmentation(img, euler, shift)
            transformed_batch.append(transformed_img)
            degEulerList_.append(euler)
            shiftFractionList_.append(shift)
            applied_transforms_ += [applied_transforms]
        return torch.stack(transformed_batch, dim=0), torch.stack(degEulerList_, dim=0), \
            torch.stack(shiftFractionList_, dim=0), applied_transforms_
    else:
        return self._applyAugmentation(imgs, degEulerList, shiftFractionList)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="cesped.datamanager.augmentations.Scheduler"><code class="flex name class">
<span>class <span class="ident">Scheduler</span></span>
<span>(</span><span>schedulerInfo)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Scheduler:
    def __init__(self, schedulerInfo):
        self.schedulerInfo = schedulerInfo

    def identity(self, x, current_step):
        return x

    def linear_up(self, p, current_step):
        maxProb = self.schedulerInfo[&#34;kwargs&#34;].get(&#34;max_prob&#34;)
        scheduler_steps = self.schedulerInfo[&#34;kwargs&#34;].get(&#34;scheduler_steps&#34;)
        increment = (maxProb - p) / scheduler_steps
        return min(p + increment * current_step, maxProb)

    def linear_down(self, p, current_step):
        scheduler_steps = self.schedulerInfo[&#34;kwargs&#34;].get(&#34;scheduler_steps&#34;)
        minProb = self.schedulerInfo[&#34;kwargs&#34;].get(&#34;min_prob&#34;)
        decrement = (p - minProb) / scheduler_steps
        return max(p - decrement * current_step, minProb)

    def generate(self):
        if self.schedulerInfo is None:
            return self.identity
        else:
            schedulerName = self.schedulerInfo[&#34;type&#34;]
            if schedulerName == &#34;linear_up&#34;:
                return self.linear_up
            elif schedulerName == &#34;linear_down&#34;:
                return self.linear_down
            else:
                raise NotImplementedError(f&#34;{schedulerName} is not valid&#34;)</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="cesped.datamanager.augmentations.Scheduler.generate"><code class="name flex">
<span>def <span class="ident">generate</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def generate(self):
    if self.schedulerInfo is None:
        return self.identity
    else:
        schedulerName = self.schedulerInfo[&#34;type&#34;]
        if schedulerName == &#34;linear_up&#34;:
            return self.linear_up
        elif schedulerName == &#34;linear_down&#34;:
            return self.linear_down
        else:
            raise NotImplementedError(f&#34;{schedulerName} is not valid&#34;)</code></pre>
</details>
</dd>
<dt id="cesped.datamanager.augmentations.Scheduler.identity"><code class="name flex">
<span>def <span class="ident">identity</span></span>(<span>self, x, current_step)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def identity(self, x, current_step):
    return x</code></pre>
</details>
</dd>
<dt id="cesped.datamanager.augmentations.Scheduler.linear_down"><code class="name flex">
<span>def <span class="ident">linear_down</span></span>(<span>self, p, current_step)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def linear_down(self, p, current_step):
    scheduler_steps = self.schedulerInfo[&#34;kwargs&#34;].get(&#34;scheduler_steps&#34;)
    minProb = self.schedulerInfo[&#34;kwargs&#34;].get(&#34;min_prob&#34;)
    decrement = (p - minProb) / scheduler_steps
    return max(p - decrement * current_step, minProb)</code></pre>
</details>
</dd>
<dt id="cesped.datamanager.augmentations.Scheduler.linear_up"><code class="name flex">
<span>def <span class="ident">linear_up</span></span>(<span>self, p, current_step)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def linear_up(self, p, current_step):
    maxProb = self.schedulerInfo[&#34;kwargs&#34;].get(&#34;max_prob&#34;)
    scheduler_steps = self.schedulerInfo[&#34;kwargs&#34;].get(&#34;scheduler_steps&#34;)
    increment = (maxProb - p) / scheduler_steps
    return min(p + increment * current_step, maxProb)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="cesped.datamanager" href="index.html">cesped.datamanager</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="cesped.datamanager.augmentations.rotTransImage" href="#cesped.datamanager.augmentations.rotTransImage">rotTransImage</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="cesped.datamanager.augmentations.Augmenter" href="#cesped.datamanager.augmentations.Augmenter">Augmenter</a></code></h4>
<ul class="">
<li><code><a title="cesped.datamanager.augmentations.Augmenter.applyAugmentation" href="#cesped.datamanager.augmentations.Augmenter.applyAugmentation">applyAugmentation</a></code></li>
<li><code><a title="cesped.datamanager.augmentations.Augmenter.read_config" href="#cesped.datamanager.augmentations.Augmenter.read_config">read_config</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="cesped.datamanager.augmentations.Scheduler" href="#cesped.datamanager.augmentations.Scheduler">Scheduler</a></code></h4>
<ul class="">
<li><code><a title="cesped.datamanager.augmentations.Scheduler.generate" href="#cesped.datamanager.augmentations.Scheduler.generate">generate</a></code></li>
<li><code><a title="cesped.datamanager.augmentations.Scheduler.identity" href="#cesped.datamanager.augmentations.Scheduler.identity">identity</a></code></li>
<li><code><a title="cesped.datamanager.augmentations.Scheduler.linear_down" href="#cesped.datamanager.augmentations.Scheduler.linear_down">linear_down</a></code></li>
<li><code><a title="cesped.datamanager.augmentations.Scheduler.linear_up" href="#cesped.datamanager.augmentations.Scheduler.linear_up">linear_up</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>