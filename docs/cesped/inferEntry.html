<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>cesped.inferEntry API documentation</title>
<meta name="description" content="This module is used to infer the pose of a benchmark entry given a trained model
Use it as CLI as &lt;br&gt;
```
python -m cesped.inferEntry â€¦" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>cesped.inferEntry</code></h1>
</header>
<section id="section-intro">
<p>This module is used to infer the pose of a benchmark entry given a trained model
Use it as CLI as <br>
<code>python -m cesped.inferEntry --data.targetName TEST --data.halfset 0 --outFname /tmp/results.star --ckpt_path /tmp/supervised/lightning_logs/version_1/checkpoints/last.ckpt</code></p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
This module is used to infer the pose of a benchmark entry given a trained model
Use it as CLI as &lt;br&gt;
    ```
python -m cesped.inferEntry --data.targetName TEST \
--data.halfset 0 \
--outFname /tmp/results.star \
--ckpt_path /tmp/supervised/lightning_logs/version_1/checkpoints/last.ckpt
    ```
&#34;&#34;&#34;

import shutil
import atexit
import os
import pickle

import os.path as osp
import sys

import argparse
import torch
from lightning import Callback, Trainer
from typing import Dict, Any, List

from lightning.pytorch.callbacks import BasePredictionWriter
from lightning.pytorch.cli import LightningArgumentParser, ArgsType

from cesped.constants import default_configs_dir
from cesped.utils.cliBuilder import MyLightningCLI, _ckpt_path_argname, CheckpointLoader
from cesped.network.plModule import PlModel
from cesped.datamanager.plDataset import ParticlesDataModule

_outname_argname = &#34;outFname&#34;


class CustomPredWriter(BasePredictionWriter):
    def __init__(self, output_dir):
        super().__init__(&#34;epoch&#34;)
        self.output_dir = output_dir

    def write_on_epoch_end(self, trainer, pl_module, predictions, batch_indices):
        batch_indices = batch_indices[0]
        count = 0
        with open(osp.join(self.output_dir, f&#34;serialized_data_{trainer.global_rank}.pkl&#34;), &#34;wb&#34;) as f:
            for predBatch, idxsBatch in zip(predictions, batch_indices):
                ids, (pred_rotmats, maxprob), metadata = predBatch
                pickle.dump(predBatch, f)
                count += 1

        print(f&#34;Partial results written by rank {trainer.global_rank} ({count})&#34;)
        trainer.strategy.barrier()

    def iter_results(self):
        for fname in os.listdir(self.output_dir):
            with open(osp.join(self.output_dir, fname), &#34;rb&#34;) as f:
                while True:
                    try:
                        item = pickle.load(f)
                        yield item
                    except EOFError:
                        break


class _MyInferLightningCLI(MyLightningCLI):
    def add_arguments_to_parser(self, parser):
        super().add_arguments_to_parser(parser)
        parser.add_argument(f&#34;--{_outname_argname}&#34;, type=str, help=&#34;The name of the output file, ended in .star&#34;,
                            required=True)


    def parse_arguments(self, parser: LightningArgumentParser, args: ArgsType) -&gt; None:

        #If the arguments provided by the user are wrong, we want to display help
        #wihtout generic arguments


        for act in parser._actions:
            if act.dest in [_outname_argname, _ckpt_path_argname, &#34;data.halfset&#34;, &#34;data.targetName&#34;]:
                act.required = True
            elif act.dest in [&#34;trainer.accelerator&#34;, &#34;trainer.devices&#34;, &#34;trainer.limit_predict_batches&#34;,
                            &#34;data.batch_size&#34;, &#34;data.num_data_workers&#34;]:
                #argument not required but configurable
                pass
            else:
                #argument that is internally loaded from checkpoint
                act.help = argparse.SUPPRESS

        super().parse_arguments(parser, args)

    def _instantiate_trainer(self, config: Dict[str, Any], callbacks: List[Callback]) -&gt; Trainer:

        outFname = self.config[_outname_argname]
        outDir = osp.join(osp.dirname(outFname), &#34;_tmp_&#34; + osp.basename(osp.splitext(outFname)[0]))
        os.makedirs(outDir, exist_ok=True)

        def remove_temp_dir(dir_path):
            if os.path.exists(dir_path):
                try:
                    shutil.rmtree(dir_path)
                    print(f&#34;Removed temporary directory: {dir_path}&#34;)
                except OSError:
                    pass
        atexit.register(remove_temp_dir, outDir)

        resultsWriter = CustomPredWriter(outDir)
        self.resultsWriter = resultsWriter
        callbacks += [resultsWriter]
        return super()._instantiate_trainer(config, callbacks)


if __name__ == &#34;__main__&#34;:

    config_fnames = [
        osp.join(default_configs_dir, &#34;defaultDataConfig.yaml&#34;),
        osp.join(default_configs_dir, &#34;defaultInferenceConfig.yaml&#34;),
    ]


    with CheckpointLoader(config_fnames) as cpk:  # TODO: Check if this works
        print(f&#34;Reading configuration from {cpk.config_fnames}&#34;)

        cli = _MyInferLightningCLI(model_class=PlModel, datamodule_class=ParticlesDataModule,
                                   save_config_callback=None,
                                   parser_kwargs={&#34;default_env&#34;: True, &#34;parser_mode&#34;: &#34;omegaconf&#34;,
                                                  &#34;default_config_files&#34;: cpk.config_fnames},
                                   run=False)
        outFname = cli.config[&#34;outFname&#34;]
        assert outFname.endswith(&#34;.star&#34;), (f&#39;Error, --outFname {outFname} not valid. Needs &#39;
                                            f&#39;to end in .star&#39;)
        assert osp.isdir(osp.dirname(outFname)), (f&#39;Error, --outFname {outFname} not valid. The directory does not &#39;
                                                  f&#39;exits!&#39;)

        cli.trainer.predict(cli.model, cli.datamodule, ckpt_path=cli.ckpt_path, return_predictions=False)

        particlesDataset = cli.datamodule.createDataset()

        cli.trainer.strategy.barrier()
        if cli.trainer.is_global_zero:
            for ids, (pred_rotmats, maxprob), metadata in cli.resultsWriter.iter_results():
                particlesDataset.updateMd(ids=ids, angles=pred_rotmats,
                                          shifts=torch.zeros(pred_rotmats.shape[0], 2, device=pred_rotmats.device),
                                          confidence=maxprob,
                                          angles_format=&#34;rotmat&#34;)
            particlesDataset.saveMd(outFname)

    &#34;&#34;&#34;
    
--data.targetName TEST \
--data.halfset 1 \
--outFname /tmp/results.star \
--ckpt_path /tmp/supervised/lightning_logs/version_0/checkpoints/last.ckpt

&#34;&#34;&#34;</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="cesped.inferEntry.CustomPredWriter"><code class="flex name class">
<span>class <span class="ident">CustomPredWriter</span></span>
<span>(</span><span>output_dir)</span>
</code></dt>
<dd>
<div class="desc"><p>Base class to implement how the predictions should be stored.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>write_interval</code></strong></dt>
<dd>When to write.</dd>
</dl>
<p>Example::</p>
<pre><code>import torch
from lightning.pytorch.callbacks import BasePredictionWriter

class CustomWriter(BasePredictionWriter):

    def __init__(self, output_dir, write_interval):
        super().__init__(write_interval)
        self.output_dir = output_dir

    def write_on_batch_end(
        self, trainer, pl_module', prediction, batch_indices, batch, batch_idx, dataloader_idx
    ):
        torch.save(prediction, os.path.join(self.output_dir, dataloader_idx, f"{batch_idx}.pt"))

    def write_on_epoch_end(self, trainer, pl_module, predictions, batch_indices):
        torch.save(predictions, os.path.join(self.output_dir, "predictions.pt"))


pred_writer = CustomWriter(output_dir="pred_path", write_interval="epoch")
trainer = Trainer(callbacks=[pred_writer])
model = BoringModel()
trainer.predict(model, return_predictions=False)
</code></pre>
<p>Example::</p>
<pre><code># multi-device inference example

import torch
from lightning.pytorch.callbacks import BasePredictionWriter

class CustomWriter(BasePredictionWriter):

    def __init__(self, output_dir, write_interval):
        super().__init__(write_interval)
        self.output_dir = output_dir

    def write_on_epoch_end(self, trainer, pl_module, predictions, batch_indices):
        # this will create N (num processes) files in &lt;code&gt;output\_dir&lt;/code&gt; each containing
        # the predictions of it's respective rank
        torch.save(predictions, os.path.join(self.output_dir, f"predictions_{trainer.global_rank}.pt"))

        # optionally, you can also save &lt;code&gt;batch\_indices&lt;/code&gt; to get the information about the data index
        # from your prediction data
        torch.save(batch_indices, os.path.join(self.output_dir, f"batch_indices_{trainer.global_rank}.pt"))


# or you can set `write_interval="batch"` and override &lt;code&gt;write\_on\_batch\_end&lt;/code&gt; to save
# predictions at batch level
pred_writer = CustomWriter(output_dir="pred_path", write_interval="epoch")
trainer = Trainer(accelerator="gpu", strategy="ddp", devices=8, callbacks=[pred_writer])
model = BoringModel()
trainer.predict(model, return_predictions=False)
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class CustomPredWriter(BasePredictionWriter):
    def __init__(self, output_dir):
        super().__init__(&#34;epoch&#34;)
        self.output_dir = output_dir

    def write_on_epoch_end(self, trainer, pl_module, predictions, batch_indices):
        batch_indices = batch_indices[0]
        count = 0
        with open(osp.join(self.output_dir, f&#34;serialized_data_{trainer.global_rank}.pkl&#34;), &#34;wb&#34;) as f:
            for predBatch, idxsBatch in zip(predictions, batch_indices):
                ids, (pred_rotmats, maxprob), metadata = predBatch
                pickle.dump(predBatch, f)
                count += 1

        print(f&#34;Partial results written by rank {trainer.global_rank} ({count})&#34;)
        trainer.strategy.barrier()

    def iter_results(self):
        for fname in os.listdir(self.output_dir):
            with open(osp.join(self.output_dir, fname), &#34;rb&#34;) as f:
                while True:
                    try:
                        item = pickle.load(f)
                        yield item
                    except EOFError:
                        break</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>lightning.pytorch.callbacks.prediction_writer.BasePredictionWriter</li>
<li>lightning.pytorch.callbacks.callback.Callback</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="cesped.inferEntry.CustomPredWriter.iter_results"><code class="name flex">
<span>def <span class="ident">iter_results</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def iter_results(self):
    for fname in os.listdir(self.output_dir):
        with open(osp.join(self.output_dir, fname), &#34;rb&#34;) as f:
            while True:
                try:
                    item = pickle.load(f)
                    yield item
                except EOFError:
                    break</code></pre>
</details>
</dd>
<dt id="cesped.inferEntry.CustomPredWriter.write_on_epoch_end"><code class="name flex">
<span>def <span class="ident">write_on_epoch_end</span></span>(<span>self, trainer, pl_module, predictions, batch_indices)</span>
</code></dt>
<dd>
<div class="desc"><p>Override with the logic to write all batches.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def write_on_epoch_end(self, trainer, pl_module, predictions, batch_indices):
    batch_indices = batch_indices[0]
    count = 0
    with open(osp.join(self.output_dir, f&#34;serialized_data_{trainer.global_rank}.pkl&#34;), &#34;wb&#34;) as f:
        for predBatch, idxsBatch in zip(predictions, batch_indices):
            ids, (pred_rotmats, maxprob), metadata = predBatch
            pickle.dump(predBatch, f)
            count += 1

    print(f&#34;Partial results written by rank {trainer.global_rank} ({count})&#34;)
    trainer.strategy.barrier()</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="cesped" href="index.html">cesped</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="cesped.inferEntry.CustomPredWriter" href="#cesped.inferEntry.CustomPredWriter">CustomPredWriter</a></code></h4>
<ul class="">
<li><code><a title="cesped.inferEntry.CustomPredWriter.iter_results" href="#cesped.inferEntry.CustomPredWriter.iter_results">iter_results</a></code></li>
<li><code><a title="cesped.inferEntry.CustomPredWriter.write_on_epoch_end" href="#cesped.inferEntry.CustomPredWriter.write_on_epoch_end">write_on_epoch_end</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>