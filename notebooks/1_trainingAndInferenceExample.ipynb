{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfeb22cd-d5cc-4f60-9876-00dde22bfb78",
   "metadata": {},
   "source": [
    "# CESPED training and inference example\n",
    "\n",
    "This notebook illustrates how to train a model on a CESPED entry and how to use the trained model to infer the poses and save them, once the model is trained. In particular, we will train the model on the test entry named \"TEST\", a reduced version of an actual entry. \n",
    "\n",
    "You can use this notebook to generate results and then, use the other notebook to evaluate the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d5d2e0-6214-4183-af67-590868f1ee77",
   "metadata": {},
   "source": [
    "First, we import the modules we will be used. As you can see, the `ParticlesDataset` class is all we need from cesped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8f5d926-b21a-414b-807e-a40d96f55394",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torchvision.models.resnet import resnet18\n",
    "from cesped.particlesDataset import ParticlesDataset\n",
    "\n",
    "device = \"cuda\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652d3950-7b6b-4645-93c3-48390eb31dec",
   "metadata": {},
   "source": [
    "Now we will see the available entries in the CESPED benchmark. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea4c03ca-b586-4413-a74a-88e1aea982b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('TEST', 0), ('TEST', 1), ('10786', 0), ('10786', 1), ('11120', 0), ('11120', 1), ('10166', 0), ('10166', 1), ('10280', 0), ('10280', 1), ('10647', 0), ('10647', 1), ('10374', 0), ('10374', 1), ('10409', 0), ('10409', 1)]\n"
     ]
    }
   ],
   "source": [
    "listOfEntries = ParticlesDataset.getCESPEDEntries()\n",
    "print(listOfEntries)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74b151c-a89f-4bcc-a88d-d60ed6eb41b8",
   "metadata": {},
   "source": [
    "Notice that each entry comes twice. This is because we have split each entry into two halves to carry out a gold standard-like evaluation procedure. In the typical cryo-EM gold standard process, each dataset is divided into two halves and each of them is processed independently until two 3D maps, generally called half-maps, are generated. Then, to assess the quality of the solution, the two half-maps are compared. \n",
    "\n",
    "Here we will do something similar. We will train a model for the half-set 0, and we will use it to predict the poses of the half-set 1. We will also train a second model using as training data the half-set 1, and we will use it to infer the poses of the half-set 0. Finally, in the next notebook, we will use the predicted poses to generate the 3D maps and evaluate the quality of the predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193c295d-460e-4fa1-8103-3dffdab61f57",
   "metadata": {},
   "source": [
    "We will work with the \"TEST\" entry, and the halfset 0. But change halfset_to_use = 1 and rerun the notebook to get predictions for the other half of the dataset. We will be saving the predicted poses in the /tmp folder, you probably want to change this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e690b1dc-dece-43d0-bbdc-d30a63159dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "targetName = \"TEST\"\n",
    "halfset_to_use = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aadcbec-adee-49b3-a68b-da1879c511d0",
   "metadata": {},
   "source": [
    "The default benchmark directory, the place where the datasets will be downloaded is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b00c1d6-60bf-4756-bfc7-bd8cfa6e8d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sanchezg/tmp/cryoSupervisedDataset\n"
     ]
    }
   ],
   "source": [
    "from cesped.constants import default_configs_dir, defaultBenchmarkDir\n",
    "print(defaultBenchmarkDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4590b13e-4c0f-4acb-b2d4-f267b4e13da2",
   "metadata": {},
   "source": [
    "Create the folder if it does not exists, or change the config files edditing the .yaml files within cesped/config and rerun the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6df61c05-e669-45c0-83b5-a9bbdcd56430",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(defaultBenchmarkDir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1ba4db-23fd-46cb-8c38-9eab1eeb516f",
   "metadata": {},
   "source": [
    "Now, we will instantiate the `ParticlesDataset` object. We will use the default benchmark directory and the desired image size. We will enable automatic normalization and ctf_correction. In addition, we will crop the particles, removing 25% of the image side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a8bedd5-8881-4f4e-878d-c2d60f77f9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ParticlesDataset(targetName, halfset_to_use,\n",
    "                           apply_perImg_normalization = True,\n",
    "                           ctf_correction = \"phase_flip\",\n",
    "                           image_size_factor_for_crop = 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5620e8-b049-41a1-a505-a6820e859818",
   "metadata": {},
   "source": [
    "Now we define a toy model and loss function for illustration purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e564b3af-c207-43f6-8cff-68bd245a4fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a toy model for predicting rotation matrices. You probably want to use something as Gramâ€“Schmidt orthonormalization\n",
    "model = torch.nn.Sequential(torch.nn.Conv2d(1, 3, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False), resnet18(),\n",
    "                            torch.nn.Linear(1000, 9))\n",
    "model = model.to(device)\n",
    "def loss_function(predR, gtR): #This is a naive loss function\n",
    "    return torch.nn.functional.mse_loss(predR.flatten(1), gtR.flatten(1))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79785ea5-0d31-46cd-b56e-5f1f3ac8d679",
   "metadata": {},
   "source": [
    "The `ParticlesDataset` objects are compatible with torch `DataLoaders`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "20f6c3e3-5570-4b5a-88dd-6c995907ae0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(dataset, batch_size=32, num_workers=0) # Change num_workers for better speed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a795b2-d83b-4cde-8806-6d6b7a58d4a6",
   "metadata": {},
   "source": [
    "Here you have an illustration of training loop. The dataset behaves as any other dataset, thus there is nothing strange in the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e0c64d1-b87c-4c5a-a971-f30a866e97a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Batch: 157/157, Loss: 0.34019476175308233\n",
      "Epoch: 2 Batch: 157/157, Loss: 0.10218479484319687\n",
      "Epoch: 3 Batch: 157/157, Loss: 0.458162993192672734\n",
      "Epoch: 4 Batch: 157/157, Loss: 0.379527360200881965\n",
      "Epoch: 5 Batch: 157/157, Loss: 0.104808010160923355\n"
     ]
    }
   ],
   "source": [
    "n_batches = len(dl)\n",
    "optimizer = Adam(model.parameters(), lr=1e-4)\n",
    "for epoch in range(5):\n",
    "    for i, batch in enumerate(dl):\n",
    "        iid, img, (rotMat, xyShiftAngs, confidence), metadata = batch\n",
    "        \n",
    "        #iid is the list of ids of the particles (string)\n",
    "        #img is a batch of Bx1xNxN images\n",
    "        #rotMat is a batch of rotation matrices Bx3x3\n",
    "        #xyShiftAngs is a batch of image shifts in Angstroms Bx2\n",
    "        #confidence is a batch of numbers, between 0 and 1, Bx1\n",
    "        #metata is a dictionary of names: values for all the information about the particle\n",
    "        img = img.to(device)\n",
    "        rotMat = rotMat.to(device)\n",
    "        predRot = model(img)\n",
    "        loss = loss_function(predRot, rotMat)\n",
    "        print(f'Epoch: {epoch + 1} Batch: {i + 1}/{n_batches}, Loss: {loss}', end='\\r')\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aceccf8-1081-4b5c-873b-0ea1561e49f9",
   "metadata": {},
   "source": [
    "Now we will perform inference on the other half-set of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e06ff0f1-b113-423a-8435-dbf6393b5bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "halfset_to_infer = (halfset_to_use + 1) %2 # This just maps 0 -> 1 and 1 -> 0, so that we use the complementary dataset\n",
    "\n",
    "#Predicted poses for the complementary dataset\n",
    "outFnamePoses = f\"/tmp/predicted_poses_{halfset_to_infer}.star\" # They will be saved using RELION star format\n",
    "toInferDataset = ParticlesDataset(targetName, halfset_to_infer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ab4454-3e70-4b98-9000-d5c8f1d24f42",
   "metadata": {},
   "source": [
    "The inference loop is quite standard. The only difference is how we update the `ParticlesDataset` object with the predicted poses. To so so, we just use the method `updateMd` providing the particle iids and the predicted angles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2cbe3860-d294-4732-b56b-ddbf3e95d22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157\n",
      "Batch: 157/157\n"
     ]
    }
   ],
   "source": [
    "i_dl = DataLoader(toInferDataset, batch_size=32, num_workers=0)\n",
    "n_batches = len(i_dl)\n",
    "print(n_batches)\n",
    "model = model.eval()\n",
    "for i, batch in enumerate(i_dl):\n",
    "    iid, img, (rotMat, xyShiftAngs, confidence), metadata = batch\n",
    "    img = img.to(device)\n",
    "\n",
    "    #This is because we are predicting the 9 values of the rotation matrix in a single row.\n",
    "    predRot = model(img).reshape(-1,3,3)\n",
    "    \n",
    "    #We are not predicting shifts or confidence scores, so we create dummy values\n",
    "    shifts=torch.zeros(predRot.shape[0],2, device=predRot.device)\n",
    "    confidence=torch.ones(predRot.shape[0])\n",
    "    \n",
    "    toInferDataset.updateMd(ids=iid, angles=predRot,\n",
    "                          shifts=torch.zeros(predRot.shape[0],2, device=predRot.device), #Or actual predictions if you have them\n",
    "                          confidence=torch.ones(predRot.shape[0]),\n",
    "                          angles_format=\"rotmat\")\n",
    "    print(f'Batch: {i + 1}/{n_batches}', end='\\r')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9621d7f-a1d9-468b-8675-049be052aa7e",
   "metadata": {},
   "source": [
    "Finally, we will save the predicted poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d01f69e-62fc-49ae-9dd6-928e6d05a99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "toInferDataset.saveMd(outFnamePoses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4323c9-8702-4c30-9bea-522768762d3a",
   "metadata": {},
   "source": [
    "That is all. Rerun the notebook with the other half-set and go to the next notebook if you want to see how to evaluate the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dc71c0-824b-4025-99dd-f6bd231e24f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
